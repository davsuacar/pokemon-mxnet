{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MXNET - MLP MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LIMIT = 200\n",
    "BATCH_SIZE = 1000\n",
    "BATCH_SIZE_TEST = 200\n",
    "NUM_CLASSES = 2\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_EPOCHS = 1000\n",
    "DROPOUT=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/data_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Name_p1', u'Type_1_p1', u'Type_2_p1', u'HP_p1', u'Attack_p1',\n",
       "       u'Defense_p1', u'SpAtk_p1', u'SpDef_p1', u'Speed_p1', u'Generation_p1',\n",
       "       u'Legendary_p1', u'Name_p2', u'Type_1_p2', u'Type_2_p2', u'HP_p2',\n",
       "       u'Attack_p2', u'Defense_p2', u'SpAtk_p2', u'SpDef_p2', u'Speed_p2',\n",
       "       u'Generation_p2', u'Legendary_p2', u'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data & Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_label = df['label']\n",
    "df_data = df.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 200\n"
     ]
    }
   ],
   "source": [
    "df_test_data = df_data[:LIMIT]\n",
    "df_test_label = df_label[:LIMIT]\n",
    "print \"Test size: \" + str(df_test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 49800\n"
     ]
    }
   ],
   "source": [
    "df_train_data = df_data[LIMIT:]\n",
    "df_train_label = df_label[LIMIT:]\n",
    "print \"Train size: \" + str(df_train_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize data iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_iter = mx.io.NDArrayIter(np.array(df_train_data), np.array(df_train_label), BATCH_SIZE, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(np.array(df_test_data), np.array(df_test_label), BATCH_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')\n",
    "data = mx.sym.Dropout(data=data, p=DROPOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The first fully-connected layer and the corresponding activation function\n",
    "fc1  = mx.sym.FullyConnected(data=data, num_hidden=128)\n",
    "act1 = mx.sym.Activation(data=fc1, act_type=\"relu\")\n",
    "\n",
    "# The second fully-connected layer and the corresponding activation function\n",
    "fc2  = mx.sym.FullyConnected(data=act1, num_hidden = 64)\n",
    "act2 = mx.sym.Activation(data=fc2, act_type=\"relu\")\n",
    "\n",
    "fc3  = mx.sym.FullyConnected(data=act2, num_hidden = 32)\n",
    "act3 = mx.sym.Activation(data=fc3, act_type=\"relu\")\n",
    "\n",
    "# POKEMON has 2 classes\n",
    "fc4  = mx.sym.FullyConnected(data=act3, num_hidden=NUM_CLASSES)\n",
    "# Softmax with cross entropy loss\n",
    "mlp  = mx.sym.SoftmaxOutput(data=fc4, name='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "mlp_model = mx.mod.Module(symbol=mlp, context=mx.cpu())\n",
    "mlp_model.fit(train_iter,  # train data\n",
    "              eval_data=val_iter,  # validation data\n",
    "              optimizer='Adam',  # use Adam to train\n",
    "              optimizer_params={'learning_rate': LEARNING_RATE},  # use fixed learning rate\n",
    "              eval_metric='acc',  # report accuracy during training\n",
    "#              batch_end_callback = mx.callback.Speedometer(BATCH_SIZE, 400), # output progress for each 100 data batches\n",
    "              num_epoch=NUM_EPOCHS)  # train for at most 10 dataset passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accuracy', 0.97)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_iter = mx.io.NDArrayIter(np.array(df_test_data), np.array(df_test_label), BATCH_SIZE_TEST)\n",
    "# predict accuracy of mlp\n",
    "acc = mx.metric.Accuracy()\n",
    "mlp_model.score(test_iter, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accuracy', 0.94456)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_iter = mx.io.NDArrayIter(np.array(df_train_data), np.array(df_train_label), BATCH_SIZE)\n",
    "# predict accuracy of mlp\n",
    "acc = mx.metric.Accuracy()\n",
    "mlp_model.score(test_iter, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
