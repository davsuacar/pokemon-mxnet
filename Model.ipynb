{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MXNET - MLP MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LIMIT = 200\n",
    "BATCH_SIZE = 500\n",
    "BATCH_SIZE_TEST = 200\n",
    "NUM_CLASSES = 2\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_EPOCHS = 1000\n",
    "DROPOUT=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/data_processed_no_normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = shuffle(df, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_exp(x):\n",
    "    return np.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['HP_1over2'] = df['HP_p1'] - df['HP_p2']\n",
    "df['Attack_1over2'] = df['Attack_p1'] - df['Attack_p2']\n",
    "df['Defense_1over2'] = df['Defense_p1'] - df['Defense_p2']\n",
    "df['SpAtk_1over2'] = df['SpAtk_p1'] - df['SpAtk_p2']\n",
    "df['SpDef_1over2'] = df['SpDef_p1'] - df['SpDef_p2']\n",
    "df['Speed_1over2'] = df['Speed_p1'] - df['Speed_p2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['HP_2over1'] = df['HP_p2'] - df['HP_p1']\n",
    "df['Attack_2over1'] = df['Attack_p2'] - df['Attack_p1']\n",
    "df['Defense_2over1'] = df['Defense_p2'] - df['Defense_p1']\n",
    "df['SpAtk_2over1'] = df['SpAtk_p2'] - df['SpAtk_p1']\n",
    "df['SpDef_2over1'] = df['SpDef_p2'] - df['SpDef_p1']\n",
    "df['Speed_2over1'] = df['Speed_p2'] - df['Speed_p1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['HP_1over2'] = df['HP_1over2'].apply(calculate_exp)\n",
    "df['Attack_1over2'] = df['Attack_1over2'].apply(calculate_exp)\n",
    "df['Defense_1over2'] = df['Defense_1over2'].apply(calculate_exp)\n",
    "df['SpAtk_1over2'] = df['SpAtk_1over2'].apply(calculate_exp)\n",
    "df['SpDef_1over2'] = df['SpDef_1over2'].apply(calculate_exp)\n",
    "df['Speed_1over2'] = df['Speed_1over2'].apply(calculate_exp)\n",
    "\n",
    "df['HP_2over1'] = df['HP_2over1'].apply(calculate_exp)\n",
    "df['Attack_2over1'] = df['Attack_2over1'].apply(calculate_exp)\n",
    "df['Defense_2over1'] = df['Defense_2over1'].apply(calculate_exp)\n",
    "df['SpAtk_2over1'] = df['SpAtk_2over1'].apply(calculate_exp)\n",
    "df['SpDef_2over1'] = df['SpDef_2over1'].apply(calculate_exp)\n",
    "df['Speed_2over1'] = df['Speed_2over1'].apply(calculate_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_normalized = preprocessing.MinMaxScaler().fit_transform(df)\n",
    "df = pd.DataFrame(df_normalized, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data & Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_label = df['label']\n",
    "df_data = df.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 200\n"
     ]
    }
   ],
   "source": [
    "df_test_data = df_data[:LIMIT]\n",
    "df_test_label = df_label[:LIMIT]\n",
    "print \"Test size: \" + str(df_test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 49800\n"
     ]
    }
   ],
   "source": [
    "df_train_data = df_data[LIMIT:]\n",
    "df_train_label = df_label[LIMIT:]\n",
    "print \"Train size: \" + str(df_train_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize data iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_iter = mx.io.NDArrayIter(np.array(df_train_data), np.array(df_train_label), BATCH_SIZE, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(np.array(df_test_data), np.array(df_test_label), BATCH_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')\n",
    "data = mx.sym.Dropout(data=data, p=DROPOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The first fully-connected layer and the corresponding activation function\n",
    "fc1  = mx.sym.FullyConnected(data=data, num_hidden=128)\n",
    "act1 = mx.sym.Activation(data=fc1, act_type=\"relu\")\n",
    "\n",
    "# The second fully-connected layer and the corresponding activation function\n",
    "fc2  = mx.sym.FullyConnected(data=act1, num_hidden = 64)\n",
    "act2 = mx.sym.Activation(data=fc2, act_type=\"relu\")\n",
    "\n",
    "fc3  = mx.sym.FullyConnected(data=act2, num_hidden = 64)\n",
    "act3 = mx.sym.Activation(data=fc3, act_type=\"relu\")\n",
    "\n",
    "fc4  = mx.sym.FullyConnected(data=act3, num_hidden = 64)\n",
    "act4 = mx.sym.Activation(data=fc4, act_type=\"relu\")\n",
    "\n",
    "fc5  = mx.sym.FullyConnected(data=act4, num_hidden = 64)\n",
    "act5 = mx.sym.Activation(data=fc5, act_type=\"relu\")\n",
    "\n",
    "# POKEMON has 2 classes\n",
    "fc6  = mx.sym.FullyConnected(data=act5, num_hidden=NUM_CLASSES)\n",
    "# Softmax with cross entropy loss\n",
    "mlp  = mx.sym.SoftmaxOutput(data=fc6, name='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "mlp_model = mx.mod.Module(symbol=mlp, context=mx.cpu())\n",
    "mlp_model.fit(train_iter,  # train data\n",
    "              eval_data=val_iter,  # validation data\n",
    "              optimizer='Adam',  # use Adam to train\n",
    "              optimizer_params={'learning_rate': LEARNING_RATE},  # use fixed learning rate\n",
    "              eval_metric='acc',  # report accuracy during training\n",
    "              #batch_end_callback = mx.callback.Speedometer(BATCH_SIZE, 400), # output progress for each 100 data batches\n",
    "              num_epoch=NUM_EPOCHS)  # train for at most 10 dataset passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_iter = mx.io.NDArrayIter(np.array(df_test_data), np.array(df_test_label), BATCH_SIZE_TEST)\n",
    "# predict accuracy of mlp\n",
    "acc = mx.metric.Accuracy()\n",
    "mlp_model.score(test_iter, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_iter = mx.io.NDArrayIter(np.array(df_train_data), np.array(df_train_label), BATCH_SIZE)\n",
    "# predict accuracy of mlp\n",
    "acc = mx.metric.Accuracy()\n",
    "mlp_model.score(test_iter, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
